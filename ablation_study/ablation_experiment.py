#!/usr/bin/env python3
"""
Milanoç½‘ç»œæµé‡é¢„æµ‹ - æ¶ˆèå®éªŒä¸»è„šæœ¬
==================================

åŸºäºåŸºçº¿æ¨¡å‹è¿›è¡Œæ¶ˆèå®éªŒï¼Œæµ‹è¯•ä¸åŒæ¨¡å‹æ¶æ„çš„æ€§èƒ½ï¼š
1. å•å‘GRU
2. å•å‘GRU+LSTM
3. çº¯LSTM
4. åŸºçº¿æ¨¡å‹(åŒå‘GRU+LSTM)
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
import json
from datetime import datetime
import sys
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥åŸºçº¿æ¨¡å‹ä»£ç 
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# å¯¼å…¥åŸºçº¿æ¨¡å‹çš„æ•°æ®å¤„ç†ç±»å’Œæ¶ˆèå®éªŒæ¨¡å‹
try:
    from optimal_features_training.milano_optimal_features_corrected import CorrectedOptimalFeaturesMilanoPredictor
    from ablation_study.models import get_model_by_name, get_all_model_info
    print("âœ… æˆåŠŸå¯¼å…¥åŸºçº¿æ¨¡å‹å’Œæ¶ˆèå®éªŒæ¨¡å‹")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿è¿è¡Œç¯å¢ƒåŒ…å«å¿…è¦çš„ä¾èµ–")
    sys.exit(1)

# è®¾ç½®éšæœºç§å­
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)

# GPUè®¾ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")


class AblationExperiment:
    """æ¶ˆèå®éªŒç±»"""
    
    def __init__(self, sequence_length=8, max_grids=300):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒ
        
        Args:
            sequence_length: åºåˆ—é•¿åº¦
            max_grids: æœ€å¤§ç½‘æ ¼æ•°é‡
        """
        self.sequence_length = sequence_length
        self.max_grids = max_grids
        
        # ä½¿ç”¨åŸºçº¿æ¨¡å‹çš„æ•°æ®å¤„ç†å™¨
        self.data_processor = CorrectedOptimalFeaturesMilanoPredictor(
            sequence_length=sequence_length, 
            max_grids=max_grids
        )
        
        self.results = {}
        
    def load_and_prepare_data(self):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print("ğŸ“¥ åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        
        # ä½¿ç”¨åŸºçº¿æ¨¡å‹çš„æ•°æ®åŠ è½½æ–¹æ³•
        data, selected_grids = self.data_processor.load_and_preprocess_data()
        
        # åˆ›å»ºåºåˆ—æ•°æ®
        features = self.data_processor.optimal_features
        X, y = self.data_processor.create_sequences(features)
        
        if X is None or len(X) < 100:
            raise ValueError("æ•°æ®åºåˆ—åˆ›å»ºå¤±è´¥æˆ–æ•°æ®é‡ä¸è¶³")
        
        print(f"åºåˆ—æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        # æ•°æ®åˆ†å‰² (70%-15%-15%)
        train_size = int(0.7 * len(X))
        val_size = int(0.15 * len(X))
        
        self.X_train = X[:train_size]
        self.y_train = y[:train_size]
        self.X_val = X[train_size:train_size + val_size]
        self.y_val = y[train_size:train_size + val_size]
        self.X_test = X[train_size + val_size:]
        self.y_test = y[train_size + val_size:]
        
        print(f"æ•°æ®åˆ†å‰²: è®­ç»ƒ{len(self.X_train)}, éªŒè¯{len(self.X_val)}, æµ‹è¯•{len(self.X_test)}")
        
        # è½¬æ¢ä¸ºTensor
        self.X_train_tensor = torch.FloatTensor(self.X_train).to(device)
        self.y_train_tensor = torch.FloatTensor(self.y_train).to(device)
        self.X_val_tensor = torch.FloatTensor(self.X_val).to(device)
        self.y_val_tensor = torch.FloatTensor(self.y_val).to(device)
        self.X_test_tensor = torch.FloatTensor(self.X_test).to(device)
        self.y_test_tensor = torch.FloatTensor(self.y_test).to(device)
        
        self.input_size = X.shape[2]
        print(f"è¾“å…¥ç‰¹å¾ç»´åº¦: {self.input_size}")
        
    def train_single_model(self, model_key, epochs=30, batch_size=32, learning_rate=0.001):
        """
        è®­ç»ƒå•ä¸ªæ¨¡å‹
        
        Args:
            model_key: æ¨¡å‹é”®å
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            
        Returns:
            dict: è®­ç»ƒå’Œè¯„ä¼°ç»“æœ
        """
        model_info = get_all_model_info()[model_key]
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ: {model_info['name']}")
        print(f"   æ¶æ„: {model_info['architecture']}")
        
        # åˆ›å»ºæ¨¡å‹
        model = get_model_by_name(model_key, self.input_size, self.sequence_length).to(device)
        
        # æ‰“å°æ¨¡å‹å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   å‚æ•°é‡: {total_params:,}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(self.X_train_tensor, self.y_train_tensor)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.MSELoss()
        
        # è®­ç»ƒæ¨¡å‹
        model.train()
        start_time = time.time()
        train_losses = []
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            batch_count = 0
            
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_X)
                loss = criterion(outputs.squeeze(), batch_y)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                batch_count += 1
            
            avg_loss = epoch_loss / batch_count
            train_losses.append(avg_loss)
            
            if (epoch + 1) % 10 == 0:
                print(f"   Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}")
        
        training_time = time.time() - start_time
        print(f"   è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.1f}ç§’")
        
        # è¯„ä¼°æ¨¡å‹
        model.eval()
        with torch.no_grad():
            val_pred = model(self.X_val_tensor).cpu().numpy().squeeze()
            test_pred = model(self.X_test_tensor).cpu().numpy().squeeze()
        
        # é€†å˜æ¢åˆ°åŸå§‹å°ºåº¦
        y_val_orig = np.expm1(self.y_val) - 1.0
        y_test_orig = np.expm1(self.y_test) - 1.0
        val_pred_orig = np.expm1(val_pred) - 1.0
        test_pred_orig = np.expm1(test_pred) - 1.0
        
        # è®¡ç®—æŒ‡æ ‡
        val_rmse = np.sqrt(mean_squared_error(y_val_orig, val_pred_orig))
        test_rmse = np.sqrt(mean_squared_error(y_test_orig, test_pred_orig))
        val_r2 = r2_score(y_val_orig, val_pred_orig)
        test_r2 = r2_score(y_test_orig, test_pred_orig)
        val_mae = mean_absolute_error(y_val_orig, val_pred_orig)
        test_mae = mean_absolute_error(y_test_orig, test_pred_orig)
        
        # è®¡ç®—MAPE
        val_mape = np.mean(np.abs((y_val_orig - val_pred_orig) / np.maximum(y_val_orig, 1e-8))) * 100
        test_mape = np.mean(np.abs((y_test_orig - test_pred_orig) / np.maximum(y_test_orig, 1e-8))) * 100
        
        # ç»“æœå­—å…¸
        results = {
            'model_key': model_key,
            'model_name': model_info['name'],
            'model_architecture': model_info['architecture'],
            'total_params': total_params,
            'training_time': training_time,
            'train_losses': train_losses,
            'val_rmse': val_rmse,
            'val_r2': val_r2,
            'val_mae': val_mae,
            'val_mape': val_mape,
            'test_rmse': test_rmse,
            'test_r2': test_r2,
            'test_mae': test_mae,
            'test_mape': test_mape,
            'y_val_true': y_val_orig,
            'y_val_pred': val_pred_orig,
            'y_test_true': y_test_orig,
            'y_test_pred': test_pred_orig,
            'model_state_dict': model.state_dict()
        }
        
        print(f"   éªŒè¯é›† - RMSE: {val_rmse:.4f}, RÂ²: {val_r2:.4f}")
        print(f"   æµ‹è¯•é›† - RMSE: {test_rmse:.4f}, RÂ²: {test_r2:.4f}")
        
        return results
    
    def run_ablation_study(self, models_to_test=None, epochs=30, batch_size=32):
        """
        è¿è¡Œå®Œæ•´çš„æ¶ˆèå®éªŒ
        
        Args:
            models_to_test: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæµ‹è¯•æ‰€æœ‰æ¨¡å‹
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        if models_to_test is None:
            models_to_test = [
                'unidirectional_gru',
                'unidirectional_gru_lstm',
                'pure_lstm',
                'baseline'
            ]
        
        print("ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ")
        print("=" * 80)
        print(f"å®éªŒé…ç½®:")
        print(f"  åºåˆ—é•¿åº¦: {self.sequence_length}")
        print(f"  æœ€å¤§ç½‘æ ¼: {self.max_grids}")
        print(f"  è®­ç»ƒè½®æ•°: {epochs}")
        print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"  æµ‹è¯•æ¨¡å‹: {len(models_to_test)} ä¸ª")
        print("=" * 80)
        
        # åŠ è½½æ•°æ®
        self.load_and_prepare_data()
        
        # é€ä¸ªè®­ç»ƒæ¨¡å‹
        for i, model_key in enumerate(models_to_test, 1):
            print(f"\nğŸ“Š å®éªŒ {i}/{len(models_to_test)}: {model_key}")
            print("-" * 50)
            
            try:
                results = self.train_single_model(
                    model_key=model_key,
                    epochs=epochs,
                    batch_size=batch_size
                )
                self.results[model_key] = results
                print(f"âœ… {results['model_name']} è®­ç»ƒå®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {model_key} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        print(f"\nğŸ¯ æ¶ˆèå®éªŒå®Œæˆ! æˆåŠŸè®­ç»ƒ {len(self.results)} ä¸ªæ¨¡å‹")
        return self.results
    
    def create_comparison_report(self):
        """åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š"""
        if not self.results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœå¯ä¾›å¯¹æ¯”")
            return None
        
        print("\nğŸ“Š åˆ›å»ºæ¶ˆèå®éªŒå¯¹æ¯”æŠ¥å‘Š...")
        
        # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
        comparison_data = []
        for model_key, results in self.results.items():
            comparison_data.append({
                'æ¨¡å‹': results['model_name'],
                'æ¶æ„': results['model_architecture'],
                'å‚æ•°é‡': results['total_params'],
                'è®­ç»ƒæ—¶é—´(ç§’)': results['training_time'],
                'éªŒè¯_RMSE': results['val_rmse'],
                'éªŒè¯_RÂ²': results['val_r2'],
                'éªŒè¯_MAE': results['val_mae'],
                'éªŒè¯_MAPE': results['val_mape'],
                'æµ‹è¯•_RMSE': results['test_rmse'],
                'æµ‹è¯•_RÂ²': results['test_r2'],
                'æµ‹è¯•_MAE': results['test_mae'],
                'æµ‹è¯•_MAPE': results['test_mape']
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # æŒ‰éªŒè¯é›†RÂ²æ’åº
        comparison_df = comparison_df.sort_values('éªŒè¯_RÂ²', ascending=False)
        
        return comparison_df
    
    def create_visualizations(self, save_dir='ablation_study/results'):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if not self.results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœå¯ä¾›å¯è§†åŒ–")
            return
        
        print("ğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ğŸ§ª æ¶ˆèå®éªŒç»“æœå¯¹æ¯”', fontsize=16, fontweight='bold')
        
        model_names = [self.results[key]['model_name'] for key in self.results.keys()]
        
        # RÂ²å¯¹æ¯”
        val_r2 = [self.results[key]['val_r2'] for key in self.results.keys()]
        test_r2 = [self.results[key]['test_r2'] for key in self.results.keys()]
        
        x = np.arange(len(model_names))
        width = 0.35
        
        axes[0, 0].bar(x - width/2, val_r2, width, label='éªŒè¯é›†', alpha=0.8)
        axes[0, 0].bar(x + width/2, test_r2, width, label='æµ‹è¯•é›†', alpha=0.8)
        axes[0, 0].set_title('RÂ² åˆ†æ•°å¯¹æ¯”')
        axes[0, 0].set_ylabel('RÂ² åˆ†æ•°')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(model_names, rotation=45)
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # RMSEå¯¹æ¯”
        val_rmse = [self.results[key]['val_rmse'] for key in self.results.keys()]
        test_rmse = [self.results[key]['test_rmse'] for key in self.results.keys()]
        
        axes[0, 1].bar(x - width/2, val_rmse, width, label='éªŒè¯é›†', alpha=0.8)
        axes[0, 1].bar(x + width/2, test_rmse, width, label='æµ‹è¯•é›†', alpha=0.8)
        axes[0, 1].set_title('RMSE å¯¹æ¯”')
        axes[0, 1].set_ylabel('RMSE')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(model_names, rotation=45)
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # å‚æ•°é‡å’Œè®­ç»ƒæ—¶é—´å¯¹æ¯”
        params = [self.results[key]['total_params'] for key in self.results.keys()]
        train_times = [self.results[key]['training_time'] for key in self.results.keys()]
        
        ax2 = axes[1, 0]
        ax2_twin = ax2.twinx()
        
        bars1 = ax2.bar(x - width/2, params, width, label='å‚æ•°é‡', alpha=0.8, color='skyblue')
        bars2 = ax2_twin.bar(x + width/2, train_times, width, label='è®­ç»ƒæ—¶é—´(ç§’)', alpha=0.8, color='lightcoral')
        
        ax2.set_title('æ¨¡å‹å¤æ‚åº¦å¯¹æ¯”')
        ax2.set_ylabel('å‚æ•°é‡', color='skyblue')
        ax2_twin.set_ylabel('è®­ç»ƒæ—¶é—´(ç§’)', color='lightcoral')
        ax2.set_xticks(x)
        ax2.set_xticklabels(model_names, rotation=45)
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ å›¾ä¾‹
        lines1, labels1 = ax2.get_legend_handles_labels()
        lines2, labels2 = ax2_twin.get_legend_handles_labels()
        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        # MAEå¯¹æ¯”
        val_mae = [self.results[key]['val_mae'] for key in self.results.keys()]
        test_mae = [self.results[key]['test_mae'] for key in self.results.keys()]
        
        axes[1, 1].bar(x - width/2, val_mae, width, label='éªŒè¯é›†', alpha=0.8)
        axes[1, 1].bar(x + width/2, test_mae, width, label='æµ‹è¯•é›†', alpha=0.8)
        axes[1, 1].set_title('MAE å¯¹æ¯”')
        axes[1, 1].set_ylabel('MAE')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(model_names, rotation=45)
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å¯¹æ¯”å›¾
        comparison_path = os.path.join(save_dir, 'ablation_study_comparison.png')
        plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š å¯¹æ¯”å›¾ä¿å­˜è‡³: {comparison_path}")
        
        # 2. ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºè¯¦ç»†çš„é¢„æµ‹å›¾
        for model_key, results in self.results.items():
            fig, axes = plt.subplots(1, 2, figsize=(15, 6))
            fig.suptitle(f'{results["model_name"]} - é¢„æµ‹ç»“æœè¯¦æƒ…', fontsize=14, fontweight='bold')
            
            # éªŒè¯é›†é¢„æµ‹ vs çœŸå®å€¼
            y_val_true = results['y_val_true']
            y_val_pred = results['y_val_pred']
            
            axes[0].scatter(y_val_true, y_val_pred, alpha=0.5, s=1)
            min_val = min(y_val_true.min(), y_val_pred.min())
            max_val = max(y_val_true.max(), y_val_pred.max())
            axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
            axes[0].set_title(f'éªŒè¯é›† (RÂ² = {results["val_r2"]:.4f})')
            axes[0].set_xlabel('çœŸå®å€¼')
            axes[0].set_ylabel('é¢„æµ‹å€¼')
            axes[0].grid(True, alpha=0.3)
            
            # æµ‹è¯•é›†é¢„æµ‹ vs çœŸå®å€¼
            y_test_true = results['y_test_true']
            y_test_pred = results['y_test_pred']
            
            axes[1].scatter(y_test_true, y_test_pred, alpha=0.5, s=1)
            min_val = min(y_test_true.min(), y_test_pred.min())
            max_val = max(y_test_true.max(), y_test_pred.max())
            axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
            axes[1].set_title(f'æµ‹è¯•é›† (RÂ² = {results["test_r2"]:.4f})')
            axes[1].set_xlabel('çœŸå®å€¼')
            axes[1].set_ylabel('é¢„æµ‹å€¼')
            axes[1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†å›¾
            model_path = os.path.join(save_dir, f'{model_key}_detailed_results.png')
            plt.savefig(model_path, dpi=300, bbox_inches='tight')
            plt.close()
        
        print(f"ğŸ“Š æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {save_dir}/")
    
    def save_results(self, save_dir='ablation_study/results'):
        """ä¿å­˜å®éªŒç»“æœ"""
        if not self.results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœå¯ä¿å­˜")
            return
        
        print("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # 1. ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        comparison_df = self.create_comparison_report()
        if comparison_df is not None:
            comparison_path = os.path.join(save_dir, 'ablation_study_comparison.csv')
            comparison_df.to_csv(comparison_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“Š å¯¹æ¯”æŠ¥å‘Š: {comparison_path}")
        
        # 2. ä¿å­˜è¯¦ç»†ç»“æœ
        summary_data = {
            'experiment_info': {
                'name': 'milano_ablation_study',
                'description': 'Milanoç½‘ç»œæµé‡é¢„æµ‹æ¶ˆèå®éªŒ',
                'datetime': datetime.now().isoformat(),
                'sequence_length': self.sequence_length,
                'max_grids': self.max_grids,
                'device': str(device)
            },
            'models_tested': list(self.results.keys()),
            'results_summary': {}
        }
        
        # 3. ä¿å­˜æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†ç»“æœ
        for model_key, results in self.results.items():
            # ä¿å­˜æ¨¡å‹çŠ¶æ€
            model_path = os.path.join(save_dir, f'{model_key}_model.pth')
            torch.save(results['model_state_dict'], model_path)
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            predictions_df = pd.DataFrame({
                'val_true': results['y_val_true'],
                'val_pred': results['y_val_pred'],
                'val_error': results['y_val_pred'] - results['y_val_true'],
                'test_true': results['y_test_true'][:len(results['y_val_true'])],
                'test_pred': results['y_test_pred'][:len(results['y_val_true'])],
                'test_error': (results['y_test_pred'] - results['y_test_true'])[:len(results['y_val_true'])]
            })
            pred_path = os.path.join(save_dir, f'{model_key}_predictions.csv')
            predictions_df.to_csv(pred_path, index=False)
            
            # æ·»åŠ åˆ°æ±‡æ€»æ•°æ®
            summary_data['results_summary'][model_key] = {
                'model_name': results['model_name'],
                'architecture': results['model_architecture'],
                'total_params': int(results['total_params']),
                'training_time': float(results['training_time']),
                'validation_metrics': {
                    'rmse': float(results['val_rmse']),
                    'r2': float(results['val_r2']),
                    'mae': float(results['val_mae']),
                    'mape': float(results['val_mape'])
                },
                'test_metrics': {
                    'rmse': float(results['test_rmse']),
                    'r2': float(results['test_r2']),
                    'mae': float(results['test_mae']),
                    'mape': float(results['test_mape'])
                }
            }
        
        # 4. ä¿å­˜æ±‡æ€»JSON
        summary_path = os.path.join(save_dir, 'ablation_study_summary.json')
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ˆ æ±‡æ€»ç»“æœ: {summary_path}")
        
        print(f"ğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜è‡³: {save_dir}/")
        
        return save_dir


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Milanoç½‘ç»œæµé‡é¢„æµ‹ - æ¶ˆèå®éªŒ")
    print("=" * 80)
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = AblationExperiment(sequence_length=8, max_grids=300)
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    results = experiment.run_ablation_study(epochs=30, batch_size=32)
    
    if not results:
        print("âŒ å®éªŒå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹")
        return
    
    # åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š
    comparison_df = experiment.create_comparison_report()
    if comparison_df is not None:
        print("\nğŸ“Š æ¶ˆèå®éªŒç»“æœæ±‡æ€»:")
        print("=" * 100)
        print(comparison_df.round(4).to_string(index=False))
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_idx = comparison_df['éªŒè¯_RÂ²'].idxmax()
        best_model = comparison_df.iloc[best_model_idx]
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['æ¨¡å‹']}")
        print(f"   éªŒè¯é›†RÂ²: {best_model['éªŒè¯_RÂ²']:.4f}")
        print(f"   æµ‹è¯•é›†RÂ²: {best_model['æµ‹è¯•_RÂ²']:.4f}")
        print(f"   å‚æ•°é‡: {best_model['å‚æ•°é‡']:,}")
        print(f"   è®­ç»ƒæ—¶é—´: {best_model['è®­ç»ƒæ—¶é—´(ç§’)']:.1f}ç§’")
    
    # åˆ›å»ºå¯è§†åŒ–
    experiment.create_visualizations()
    
    # ä¿å­˜ç»“æœ
    save_dir = experiment.save_results()
    
    print(f"\nğŸ¯ æ¶ˆèå®éªŒå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {save_dir}")
    print(f"ğŸ” æŸ¥çœ‹å¯¹æ¯”å›¾: {save_dir}/ablation_study_comparison.png")


if __name__ == "__main__":
    main()